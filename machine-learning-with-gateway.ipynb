{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask for Machine Learning\n",
    "\n",
    "This is a high-level overview demonstrating some the components of Dask-ML.\n",
    "Visit the main [Dask-ML](http://ml.dask.org) documentation, see the [dask tutorial](https://github.com/dask/dask-tutorial) notebook 08, or explore some of the other machine-learning examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client, progress\n",
    "# client = Client(processes=False, threads_per_worker=4,\n",
    "#                 n_workers=1, memory_limit='2GB')\n",
    "# clients\n",
    "\n",
    "from tools import init_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scikit-Learn Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use scikit-learn to create a pair of small random arrays, one for the features `X`, and one for the target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06377997,  0.67640868,  1.06935647, -0.21758002,  0.46021477,\n",
       "        -0.39916689, -0.07918751,  1.20938491, -0.78531472, -0.17218611,\n",
       "        -1.08535744, -0.99311895,  0.30693511,  0.06405769, -1.0542328 ,\n",
       "        -0.52749607, -0.0741832 , -0.35562842,  1.05721416, -0.90259159],\n",
       "       [ 0.0708476 , -1.69528125,  2.44944917, -0.5304942 , -0.93296221,\n",
       "         2.86520354,  2.43572851, -1.61850016,  1.30071691,  0.34840246,\n",
       "         0.54493439,  0.22532411,  0.60556322, -0.19210097, -0.06802699,\n",
       "         0.9716812 , -1.79204799,  0.01708348, -0.37566904, -0.62323644],\n",
       "       [ 0.94028404, -0.49214582,  0.67795602, -0.22775445,  1.40175261,\n",
       "         1.23165333, -0.77746425,  0.01561602,  1.33171299,  1.08477266,\n",
       "        -0.97805157, -0.05012039,  0.94838552, -0.17342825, -0.47767184,\n",
       "         0.76089649,  1.00115812, -0.06946407,  1.35904607, -1.18958963],\n",
       "       [-0.29951677,  0.75988955,  0.18280267, -1.55023271,  0.33821802,\n",
       "         0.36324148, -2.10052547, -0.4380675 , -0.16639343, -0.34083531,\n",
       "         0.42435643,  1.17872434,  2.8314804 ,  0.14241375, -0.20281911,\n",
       "         2.40571546,  0.31330473,  0.40435568, -0.28754632, -2.8478034 ],\n",
       "       [-2.63062675,  0.23103376,  0.04246253,  0.47885055,  1.54674163,\n",
       "         1.6379556 , -1.53207229, -0.73444479,  0.46585484,  0.4738362 ,\n",
       "         0.98981401, -1.06119392, -0.88887952,  1.23840892, -0.57282854,\n",
       "        -1.27533949,  1.0030065 , -0.47712843,  0.09853558,  0.52780407]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit a [Support Vector Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), using [grid search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find the best value of the $C$ hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.logspace(0.001, 10, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00230524e+00, 1.80877529e+00, 3.26414341e+00, 5.89052287e+00,\n",
       "       1.06301272e+01, 1.91832893e+01, 3.46184558e+01, 6.24729922e+01,\n",
       "       1.12739713e+02, 2.03451801e+02, 3.67152216e+02, 6.62568476e+02,\n",
       "       1.19568116e+03, 2.15774441e+03, 3.89389840e+03, 7.02698831e+03,\n",
       "       1.26810100e+04, 2.28843437e+04, 4.12974349e+04, 7.45259794e+04,\n",
       "       1.34490717e+05, 2.42703994e+05, 4.37987321e+05, 7.90398585e+05,\n",
       "       1.42636531e+06, 2.57404055e+06, 4.64515275e+06, 8.38271335e+06,\n",
       "       1.51275721e+07, 2.72994468e+07, 4.92649971e+07, 8.89043635e+07,\n",
       "       1.60438167e+08, 2.89529158e+08, 5.22488725e+08, 9.42891104e+08,\n",
       "       1.70155564e+09, 3.07065320e+09, 5.54134749e+09, 1.00000000e+10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": C,\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit that normally, we would call\n",
    "\n",
    "```python\n",
    "grid_search.fit(X, y)\n",
    "```\n",
    "\n",
    "To fit it using the cluster, we just need to use a context manager provided by joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 s, sys: 27.5 ms, total: 40.8 s\n",
      "Wall time: 40.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=SVC(gamma='auto', probability=True, random_state=0),\n",
       "             iid=True, n_jobs=1,\n",
       "             param_grid={'C': array([1.00230524e+00, 1.80877529e+00, 3.26414341e+00, 5.89052287e+00,\n",
       "       1.06301272e+01, 1.91832893e+01, 3.46184558e+01, 6.24729922e+01,\n",
       "       1.12739713e+02, 2.03451801e+02, 3.67152216e+02, 6.62568476e+02,\n",
       "       1.19568116e+03, 2.15774441e+03, 3.89389840e+03, 7.0269...\n",
       "       1.34490717e+05, 2.42703994e+05, 4.37987321e+05, 7.90398585e+05,\n",
       "       1.42636531e+06, 2.57404055e+06, 4.64515275e+06, 8.38271335e+06,\n",
       "       1.51275721e+07, 2.72994468e+07, 4.92649971e+07, 8.89043635e+07,\n",
       "       1.60438167e+08, 2.89529158e+08, 5.22488725e+08, 9.42891104e+08,\n",
       "       1.70155564e+09, 3.07065320e+09, 5.54134749e+09, 1.00000000e+10]),\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid'],\n",
       "                         'shrinking': [True, False]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, client = init_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280d502a133946ccbf970efb85ee2f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": C,\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 107 ms, total: 1.57 s\n",
      "Wall time: 2.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit 48 different models, one for each hyper-parameter combination in `param_grid`, distributed across the cluster. At this point, we have a regular scikit-learn model, which can be used for prediction, scoring, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.predict(X)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on training scikit-learn models with distributed joblib, see the [dask-ml documentation](http://dask-ml.readthedocs.io/en/latest/joblib.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Large Datasets\n",
    "\n",
    "Most estimators in scikit-learn are designed to work on in-memory arrays. Training with larger datasets may require different algorithms.\n",
    "\n",
    "All of the algorithms implemented in Dask-ML work well on larger than memory datasets, which you might store in a [dask array](http://dask.pydata.org/en/latest/array.html) or [dataframe](http://dask.pydata.org/en/latest/dataframe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.datasets\n",
    "import dask_ml.cluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll use `dask_ml.datasets.make_blobs` to generate some random *dask* arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dask_ml.datasets.make_blobs(n_samples=10000000,\n",
    "                                   chunks=1000000,\n",
    "                                   random_state=0,\n",
    "                                   centers=3)\n",
    "X = X.persist()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the k-means implemented in Dask-ML to cluster the points. It uses the `k-means||` (read: \"k-means parallel\") initialization algorithm, which scales better than `k-means++`. All of the computation, both during and after initialization, can be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = dask_ml.cluster.KMeans(n_clusters=3, init_max_iter=2, oversampling_factor=10)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot a sample of points, colored by the cluster each falls into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[::10000, 0], X[::10000, 1], marker='.', c=km.labels_[::10000],\n",
    "           cmap='viridis', alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the estimators implemented in Dask-ML, see the [API documentation](http://dask-ml.readthedocs.io/en/latest/modules/api.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
